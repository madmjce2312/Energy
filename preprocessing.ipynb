{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madmjce2312/Energy/blob/main/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9RPeSb3ugHM"
      },
      "source": [
        "# Setup Môi Trường"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1llWKU30Mmez"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLhf2Y-yM1TB"
      },
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/PalmDetection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBR1EsDMnMCC"
      },
      "source": [
        "# !unzip -q abc.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bRSVSOUM9lo"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SidVPpH4lMe0"
      },
      "source": [
        "!pip install mediapipe\n",
        "# !pip install keras==2.3.1\n",
        "# !pip install tensorflow==2.5.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HqhiQWLu2yU"
      },
      "source": [
        "# Xử lý dữ liệu (tín hiệu số)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7TI_D2JM-SG"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn1FxYhKsM8L"
      },
      "source": [
        "mp_draw = mp.solutions.drawing_utils\n",
        "mp_hand = mp.solutions.hands"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YrvZqqYaSGv"
      },
      "source": [
        "hand = mp_hand.Hands(max_num_hands=1, min_detection_confidence=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsmUyxi2Ie7W"
      },
      "source": [
        "def get_lm(img, hand=hand):\n",
        "    results = hand.process(img)\n",
        "    if not results.multi_hand_landmarks:\n",
        "        return None\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-u-e5FAHo8f"
      },
      "source": [
        "def preprocess(img, hand=hand, desiredHandWidth=221, desiredHandHeight=221):\n",
        "    # BRG -> RGB\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    results = get_lm(img)\n",
        "    if results is None:\n",
        "        return None\n",
        "    \n",
        "    # Flip if hand is upside down\n",
        "    wrist = results.multi_hand_landmarks[0].landmark[0]\n",
        "    if_mcp = results.multi_hand_landmarks[0].landmark[5]\n",
        "    mf_mcp = results.multi_hand_landmarks[0].landmark[9]\n",
        "    rf_mcp = results.multi_hand_landmarks[0].landmark[13]\n",
        "    pf_mcp = results.multi_hand_landmarks[0].landmark[17]\n",
        "\n",
        "    if all(y.y > wrist.y for y in [if_mcp, mf_mcp, rf_mcp, pf_mcp]):\n",
        "        img = cv2.flip(img, 0)\n",
        "\n",
        "    # Rotate to straight-up\n",
        "    results = get_lm(img)\n",
        "    if results is None:\n",
        "        return None\n",
        "    \n",
        "    wrist = results.multi_hand_landmarks[0].landmark[0]\n",
        "    if_mcp = results.multi_hand_landmarks[0].landmark[5]\n",
        "    mf_mcp = results.multi_hand_landmarks[0].landmark[9]\n",
        "    rf_mcp = results.multi_hand_landmarks[0].landmark[13]\n",
        "    pf_mcp = results.multi_hand_landmarks[0].landmark[17]\n",
        "\n",
        "    if all(x.x > wrist.x for x in [if_mcp, mf_mcp, rf_mcp, pf_mcp]):\n",
        "        img = cv2.rotate(img, cv2.cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "\n",
        "    if all(x.x < wrist.x for x in [if_mcp, mf_mcp, rf_mcp, pf_mcp]):\n",
        "        img = cv2.rotate(img, cv2.cv2.ROTATE_90_CLOCKWISE)\n",
        "    \n",
        "    # Flip if to left handed\n",
        "    results = get_lm(img)\n",
        "    if results is None:\n",
        "        return None\n",
        "    \n",
        "    tf_mcp = results.multi_hand_landmarks[0].landmark[2]\n",
        "    pf_mcp = results.multi_hand_landmarks[0].landmark[17]\n",
        "\n",
        "    if tf_mcp.x > pf_mcp.x:\n",
        "        img = cv2.flip(img, 1)\n",
        "    \n",
        "    # Align hand\n",
        "    results = get_lm(img)\n",
        "    if results is None:\n",
        "        return None\n",
        "\n",
        "    if_mcp = results.multi_hand_landmarks[0].landmark[5]\n",
        "    pf_mcp = results.multi_hand_landmarks[0].landmark[17]\n",
        "\n",
        "    if_mcp.x, if_mcp.y = if_mcp.x*w, if_mcp.y*h\n",
        "    pf_mcp.x, pf_mcp.y = pf_mcp.x*w, pf_mcp.y*h\n",
        "\n",
        "    root = ((if_mcp.x + pf_mcp.x)//2, (if_mcp.y + pf_mcp.y)//2)\n",
        "\n",
        "    dY = pf_mcp.y - if_mcp.y\n",
        "    dX = pf_mcp.x - if_mcp.x\n",
        "    angle = np.degrees(np.arctan2(dY, dX))\n",
        "\n",
        "    if abs(angle) > 90:\n",
        "        angle -= 180\n",
        "\n",
        "    dist = np.sqrt(dY**2 + dX**2)\n",
        "    desiredDist = 0.8 * desiredHandWidth\n",
        "    scale = desiredDist / dist\n",
        "\n",
        "    M = cv2.getRotationMatrix2D(root, angle, scale)\n",
        "\n",
        "    tX = desiredHandWidth * 0.5\n",
        "    tY = desiredHandHeight * 0.3\n",
        "    \n",
        "    M[0,2] += tX - root[0]\n",
        "    M[1,2] += tY - root[1]\n",
        "    \n",
        "    aligned = cv2.warpAffine(img, M, (desiredHandWidth, desiredHandHeight), flags=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Get palm\n",
        "    gauss = cv2.GaussianBlur(aligned, (5,5), cv2.BORDER_DEFAULT)\n",
        "\n",
        "    gray = cv2.cvtColor(gauss, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    eq_gray = cv2.equalizeHist(gray)\n",
        "\n",
        "    # # histogram equalization rgb\n",
        "    # img_yuv = cv2.cvtColor(aligned, cv2.COLOR_RGB2YUV)\n",
        "    # img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
        "    # img_output = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
        "\n",
        "    canny = cv2.Canny(eq_gray, 100, 200)\n",
        "\n",
        "    return canny"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOA8ohTTNEEQ"
      },
      "source": [
        "def preprocess_and_save(input_path, output_path):\n",
        "    for ppl in os.listdir(input_path):\n",
        "        if not os.path.exists(f'{output_path}/{ppl}'):\n",
        "            os.mkdir(f'{output_path}/{ppl}')\n",
        "        print(ppl)\n",
        "        for img_name in os.listdir(f'{input_path}/{ppl}'):\n",
        "            print(img_name)\n",
        "            img = cv2.imread(f'{input_path}/{ppl}/{img_name}')\n",
        "            canny = preprocess(img)\n",
        "\n",
        "            if canny is None:\n",
        "                continue\n",
        "\n",
        "            cv2.imwrite(f'{output_path}/{ppl}/{img_name}', canny)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PlzGCx5xoNC"
      },
      "source": [
        "# preprocess real_db\n",
        "preprocess_and_save(input_path='./data/Real_Db', output_path='./data/aligned')\n",
        "\n",
        "# preprocess NotDb\n",
        "preprocess_and_save(input_path='./data/NotDb', output_path='./data/aligned_NotDb')\n",
        "\n",
        "# preprocess real_db\n",
        "preprocess_and_save(input_path='./data/InDb', output_path='./data/aligned_InDb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yZQhwowyNmV"
      },
      "source": [
        "# Training feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK0nbBwAC8mb"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zKJP_oPmqY3"
      },
      "source": [
        "def convnet_model_():\n",
        "    # vgg_model = keras.applications.VGG16(weights=None, include_top=False, input_shape=(221, 221, 3))\n",
        "    # x = vgg_model.output\n",
        "    cnn_input = Input(shape=(221, 221, 1))\n",
        "    x = Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(cnn_input)\n",
        "    x = MaxPool2D(pool_size=(3,3), padding='same')(x)\n",
        "    x = Conv2D(128, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
        "    x = MaxPool2D(pool_size=(3,3), padding='same')(x)\n",
        "    x = Conv2D(256, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
        "    x = MaxPool2D(pool_size=(3,3), padding='same')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.6)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.6)(x)\n",
        "    x = tf.nn.l2_normalize(x, axis=1)\n",
        "    # x = Lambda(lambda x_: tf.math.l2_normalize(x,axis=1))(x)\n",
        "#     x = Lambda(K.l2_normalize)(x)\n",
        "    convnet_model = Model(inputs=cnn_input, outputs=x)\n",
        "    return convnet_model\n",
        "\n",
        "def deep_rank_model():\n",
        "    convnet_model = convnet_model_()\n",
        "\n",
        "    first_input = Input(shape=(221, 221, 1))\n",
        "    first_conv = Conv2D(64, kernel_size=(3,3), strides=(16,16), padding='same', activation='relu')(first_input)\n",
        "    first_max = MaxPool2D(pool_size=(3,3), strides=(2,2), padding='same')(first_conv)\n",
        "    first_max = Flatten()(first_max)\n",
        "    first_max = tf.nn.l2_normalize(first_max, axis=1)\n",
        "\n",
        "    second_input = Input(shape=(221, 221, 1))\n",
        "    second_conv = Conv2D(64, kernel_size=(3,3), strides=(32,32), padding='same', activation='relu')(second_input)\n",
        "    second_max = MaxPool2D(pool_size=(3,3), strides=(2,2), padding='same')(second_conv)\n",
        "    second_max = Flatten()(second_max)\n",
        "    second_max = tf.nn.l2_normalize(second_max, axis=1)\n",
        "                       \n",
        "    merge_one = concatenate([first_max, second_max])\n",
        "    merge_two = concatenate([merge_one, convnet_model.output])\n",
        "    emb = Dense(256)(merge_two)\n",
        "    emb = Dense(128)(emb)\n",
        "    l2_norm_final = tf.nn.l2_normalize(emb, axis=1)\n",
        "                        \n",
        "    final_model = Model(inputs=[first_input, second_input, convnet_model.input], outputs=l2_norm_final)\n",
        "\n",
        "    return final_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slSlbML1rn25"
      },
      "source": [
        "# Xem cấu trúc model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "model = deep_rank_model()\n",
        "model.summary()\n",
        "plot_model(model, to_file='model_feature_extraction.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff32nG65qKcP"
      },
      "source": [
        "batch_size = 24\n",
        "_EPSILON = 1e-7\n",
        "\n",
        "def _loss_tensor(y_true, y_pred):\n",
        "    y_pred = tf.clip_by_value(y_pred, _EPSILON, 1.0 - _EPSILON)\n",
        "    loss = 0.\n",
        "    g = 1.\n",
        "    for i in range(0, batch_size, 3):\n",
        "        try:\n",
        "            q_embedding = y_pred[i]\n",
        "            p_embedding = y_pred[i+1]\n",
        "            n_embedding = y_pred[i+2]\n",
        "            D_q_p = tf.math.sqrt(tf.math.reduce_sum((q_embedding - p_embedding)**2))\n",
        "            D_q_n = tf.math.sqrt(tf.math.reduce_sum((q_embedding - n_embedding)**2))\n",
        "            loss = loss + g + D_q_p - D_q_n\n",
        "        except:\n",
        "            continue\n",
        "    loss = loss/batch_size*3\n",
        "    return tf.math.maximum(loss, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DOGQQCkrB5c"
      },
      "source": [
        "def image_generator(img_path, batch_size=24):\n",
        "    identities = os.listdir(img_path)\n",
        "    anchor_id = 0\n",
        "    while True:\n",
        "        input_queue = []\n",
        "\n",
        "        for i in range(batch_size//3):\n",
        "\n",
        "            idp = identities[anchor_id%len(identities)]\n",
        "            idn = random.choice(identities)\n",
        "            while idn == idp:\n",
        "                idn = random.choice(identities)\n",
        "            anchor_id += 1\n",
        "\n",
        "            input_queue += [np.expand_dims(cv2.imread(f'{img_path}/{idp}/{img_name}', cv2.IMREAD_UNCHANGED)/255.0, 2) for img_name in random.sample(os.listdir(f'{img_path}/{idp}'), 2)]\n",
        "            input_queue += [np.expand_dims(cv2.imread(f'{img_path}/{idn}/{img_name}', cv2.IMREAD_UNCHANGED)/255.0, 2) for img_name in random.sample(os.listdir(f'{img_path}/{idn}'), 1)]\n",
        "\n",
        "        input_queue = np.array(input_queue)\n",
        "\n",
        "        yield ([input_queue, input_queue, input_queue], np.zeros((batch_size, )))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS378yEEz0iQ"
      },
      "source": [
        "gen = image_generator('./data/aligned')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EPi13ThhGQJ"
      },
      "source": [
        "l = next(gen)\n",
        "print(l[0][0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMNsxkm2azRc"
      },
      "source": [
        "model.compile(loss=_loss_tensor, optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6kQiQX_vcrW"
      },
      "source": [
        "cb_es = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drNQBTLsbl80"
      },
      "source": [
        "# Train 800 epochs without callback for firm performance\n",
        "# Save model each 200 epochs\n",
        "for i in range(4):\n",
        "    model.fit_generator(generator=gen,\n",
        "                    steps_per_epoch=300//batch_size,\n",
        "                    epochs=200,\n",
        "                    verbose=1)\n",
        "    model.save_weights(f'./model/model64-{i}-2408.h5')\n",
        "\n",
        "# Train 100 epochs with callback for best performance\n",
        "model.fit_generator(generator=gen,\n",
        "                   steps_per_epoch=360//batch_size,\n",
        "                   epochs=100,\n",
        "                   callbacks=[cb_es],\n",
        "                   verbose=1)\n",
        "model.save('./model/model128-best-2408.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7ajRbPC4hs1"
      },
      "source": [
        "# Training classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agkfJpPpci81"
      },
      "source": [
        "md = deep_rank_model()\n",
        "md.load_weights('./model/model128-best-2408.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq_ZK2dpcRt7"
      },
      "source": [
        "# root_palm = {}\n",
        "for person in os.listdir('./data/aligned'):\n",
        "    if not os.path.exists(f'./data/emb/{person}'):\n",
        "        os.mkdir(f'./data/emb/{person}')\n",
        "    avg = 0\n",
        "    count = 0\n",
        "    for img_name in os.listdir(f'./data/aligned/{person}'):\n",
        "        s1 = cv2.imread(f'./data/aligned/{person}/{img_name}', cv2.IMREAD_UNCHANGED)\n",
        "        s1 = s1/255.0\n",
        "        ip = np.expand_dims(s1, axis=2)\n",
        "        ip = np.expand_dims(ip, axis=0)\n",
        "        with open(f'./data/emb/{person}/{person}_{count}.txt', 'w+') as f:\n",
        "            f.write(str([x for x in list(md.predict([ip, ip, ip])[0])]))\n",
        "            f.close()\n",
        "        \n",
        "        # root_palm[person] = [str(x) for x in list(md.predict([ip, ip, ip])[0])]\n",
        "        # break\n",
        "    #     avg += md.predict([ip, ip, ip])[0]\n",
        "        count += 1\n",
        "    # avg = avg/count\n",
        "    # root_palm[person] = [str(x) for x in list(avg)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfNMPQ1BAAQd"
      },
      "source": [
        "import ast\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def get_all_emb(data_path='./data/emb'):\n",
        "    X = []\n",
        "    y = []\n",
        "    classes = {p:i for i,p in enumerate(os.listdir('./data/emb'))}\n",
        "    for person in os.listdir(data_path):\n",
        "        for txt in os.listdir(os.path.join(data_path, person)):\n",
        "            f = open(os.path.join(data_path, person, txt), 'r')\n",
        "            temp = f.read()\n",
        "            f.close()\n",
        "            X.append(np.array(ast.literal_eval(temp)))\n",
        "        y += [classes[person]]*len(os.listdir(os.path.join(data_path, person)))\n",
        "      \n",
        "    return np.array(X), np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Uf3AqJbFkaz"
      },
      "source": [
        "X, y = get_all_emb()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4juEfLSGLMl"
      },
      "source": [
        "y = to_categorical(y, len(os.listdir('./data/emb')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg-UJnepJTsp"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9SGg1HtG2Hj"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEVhSan8HHey"
      },
      "source": [
        "# Classification model\n",
        "def init_dnn_classify(emb_size=128, num_classes=len(os.listdir('./data/emb'))):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(emb_size,)))\n",
        "    # model.add(Dropout(0.2))\n",
        "    # model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    # model.add(Dropout(0.2))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCirH9oqIQ2y"
      },
      "source": [
        "# Xem cấu trúc model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "dnn = init_dnn_classify()\n",
        "# dnn.summary()\n",
        "plot_model(dnn, to_file='model_classification.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRzDP2QcIbRp"
      },
      "source": [
        "dnn.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUuYoSsqIomg"
      },
      "source": [
        "dnn.fit(X, y, batch_size=16, epochs=100, validation_split=0.2)\n",
        "dnn.save('./model/dnn_2408.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO2Q65Ih8l-H"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owo3Kq2ZeN-c"
      },
      "source": [
        "# import json\n",
        "# # write json root_palm\n",
        "# with open('result.json', 'w') as fp:\n",
        "#     json.dump(root_palm, fp)\n",
        "#     fp.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOmMB6pqvlpq"
      },
      "source": [
        "# # read json root_palm\n",
        "# f = open('result.json', 'r')\n",
        "# root_palm = {key:np.array([float(x) for x in value]) for key, value in json.load(f).items()}\n",
        "# f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBi9VNQMud5z"
      },
      "source": [
        "classes_inv = {i:p for i,p in enumerate(os.listdir('./data/emb'))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19gwEF3bbQVe"
      },
      "source": [
        "# Test InDb\n",
        "for per in os.listdir('./data/InDb'):\n",
        "    print(\"Ground truth: \", per)\n",
        "    for img_name in os.listdir(f'./data/InDb/{per}'):\n",
        "        img = cv2.imread(f'./data/InDb/{per}/{img_name}', cv2.IMREAD_UNCHANGED)\n",
        "        img_canny = preprocess(img)\n",
        "        if img_canny is not None:\n",
        "            img_canny = img_canny/255.0\n",
        "            ip = np.expand_dims(img_canny, axis=2)\n",
        "            ip = np.expand_dims(ip, axis=0)\n",
        "\n",
        "            emb = md.predict([ip, ip, ip])\n",
        "\n",
        "            # result = min({per:np.linalg.norm(emb-val) for per,val in root_palm.items()}.items(), key = lambda x: x[1])\n",
        "\n",
        "            prediction = dnn.predict(emb)[0]\n",
        "            # print(prediction)\n",
        "            predicted_person = classes_inv[np.argmax(prediction, 0)]\n",
        "\n",
        "            if np.max(prediction, 0) < 0.5:\n",
        "                print(\"Day la nguoi la\")\n",
        "            else:\n",
        "                print(f\"Day la {np.max(prediction, 0)} {predicted_person}\")\n",
        "        else:\n",
        "            print(\"Cannot detect hand\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPjjA9NLbkBf"
      },
      "source": [
        "# Test NotDb\n",
        "for per in os.listdir('./data/NotDb'):\n",
        "    print(\"Ground truth: \", per)\n",
        "    for img_name in os.listdir(f'./data/NotDb/{per}'):\n",
        "        img = cv2.imread(f'./data/NotDb/{per}/{img_name}', cv2.IMREAD_UNCHANGED)\n",
        "        img_canny = preprocess(img)\n",
        "        if img_canny is not None:\n",
        "            img_canny = img_canny/255.0\n",
        "            ip = img_canny\n",
        "            ip = np.expand_dims(ip, axis=0)\n",
        "\n",
        "            emb = md.predict([ip, ip, ip])\n",
        "\n",
        "            # result = min({per:np.linalg.norm(emb-val) for per,val in root_palm.items()}.items(), key = lambda x: x[1])\n",
        "            prediction = dnn.predict(emb)[0]\n",
        "            # print(prediction)\n",
        "            predicted_person = classes_inv[np.argmax(prediction, 0)]\n",
        "\n",
        "            if np.max(prediction, 0) < 0.9:\n",
        "                print(\"Day la nguoi la\")\n",
        "            else:\n",
        "                print(f\"Day la {np.max(prediction, 0)} {predicted_person}\")\n",
        "        else:\n",
        "            print(\"Cannot detect hand\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6ij9ypVbvA9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}